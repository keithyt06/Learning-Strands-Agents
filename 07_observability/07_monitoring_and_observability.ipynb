{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Monitoring and Observability in Strands Agents\n",
    "\n",
    "## Introduction to Agent Observability\n",
    "\n",
    "As you deploy Strands Agents into production environments, understanding how they're performing, debugging issues, and ensuring reliable operation becomes critical. This chapter focuses on monitoring and observability techniques for Strands Agents, helping you build reliable AI systems that can be effectively maintained in production.\n",
    "\n",
    "We'll cover:\n",
    "- Logging full lifecycle actions\n",
    "- Monitoring performance and latency\n",
    "- Tracing agent operations\n",
    "\n",
    "As with previous chapters, we'll use the Nova Lite model (`us.amazon.nova-lite-v1:0`) as specified for our course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Prerequisites\n",
    "\n",
    "Let's start by installing the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U strands-agents strands-agents-tools\n",
    "%pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n",
    "\n",
    "Strands Agents provide built-in capabilities for logging agent operations. Let's start with some basic logging approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure the root strands logger\n",
    "logging.getLogger(\"strands\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands_tools import current_time\n",
    "\n",
    "# Create a simple agent\n",
    "simple_agent = Agent(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",  # Using Nova Lite model\n",
    "    tools=[current_time],\n",
    "    system_prompt=\"You are a helpful assistant that provides clear and informative responses.\"\n",
    ")\n",
    "\n",
    "result = simple_agent(\"What's the time in London?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a handler to see the logs\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s | %(name)s | %(message)s\", \n",
    "    handlers=[logging.StreamHandler()],\n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentObservabilityMiddleware:\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            \"total_calls\": 0,\n",
    "            \"total_tool_calls\": 0,\n",
    "            \"total_errors\": 0,\n",
    "            \"total_execution_time\": 0,\n",
    "            \"tool_usage\": {}\n",
    "        }\n",
    "    \n",
    "    def __call__(self, next_handler):\n",
    "        def handle(agent_instance, query, **kwargs):\n",
    "            # Pre-processing\n",
    "            self.metrics[\"total_calls\"] += 1\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                # Execute the agent\n",
    "                response = next_handler(agent_instance, query, **kwargs)\n",
    "                \n",
    "                # Post-processing\n",
    "                execution_time = time.time() - start_time\n",
    "                self.metrics[\"total_execution_time\"] += execution_time\n",
    "                \n",
    "                # Track tool usage\n",
    "                tool_calls = getattr(response, 'tool_calls', [])\n",
    "                self.metrics[\"total_tool_calls\"] += len(tool_calls)\n",
    "                \n",
    "                for call in tool_calls:\n",
    "                    tool_name = call.tool_name\n",
    "                    if tool_name not in self.metrics[\"tool_usage\"]:\n",
    "                        self.metrics[\"tool_usage\"][tool_name] = 0\n",
    "                    self.metrics[\"tool_usage\"][tool_name] += 1\n",
    "                \n",
    "                return response\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.metrics[\"total_errors\"] += 1\n",
    "                raise\n",
    "        \n",
    "        return handle\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        # Calculate average execution time\n",
    "        avg_time = 0\n",
    "        if self.metrics[\"total_calls\"] > 0:\n",
    "            avg_time = self.metrics[\"total_execution_time\"] / self.metrics[\"total_calls\"]\n",
    "        \n",
    "        # Add calculated metrics\n",
    "        metrics = self.metrics.copy()\n",
    "        metrics[\"average_execution_time\"] = avg_time\n",
    "        metrics[\"error_rate\"] = self.metrics[\"total_errors\"] / max(1, self.metrics[\"total_calls\"])\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our middleware with a Strands Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom tool for testing\n",
    "@tool\n",
    "def weather_info(location: str) -> str:\n",
    "    \"\"\"Get weather information for a specified location.\"\"\"\n",
    "    # Mock data for demonstration\n",
    "    weather_data = {\n",
    "        \"new york\": \"72°F, Partly Cloudy\",\n",
    "        \"london\": \"64°F, Rainy\",\n",
    "        \"tokyo\": \"78°F, Sunny\",\n",
    "        \"sydney\": \"70°F, Clear\",\n",
    "        \"paris\": \"68°F, Cloudy\"\n",
    "    }\n",
    "    return weather_data.get(location.lower(), \"Weather information not available\")\n",
    "\n",
    "# Create an observable agent\n",
    "middleware = AgentObservabilityMiddleware()\n",
    "observable_agent = Agent(\n",
    "    model=\"us.amazon.nova-pro-v1:0\",\n",
    "    tools=[calculator, weather_info],\n",
    "    system_prompt=\"You are a helpful assistant that can check weather and perform calculations.\",\n",
    "    middleware=[middleware]\n",
    ")\n",
    "\n",
    "# Run some test queries\n",
    "queries = [\n",
    "    \"What's the weather like in Tokyo?\",\n",
    "    \"Calculate 573 * 218\",\n",
    "    \"What's the weather in Paris and how much is 100 * 1.2?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    response = observable_agent(query)\n",
    "    print(f\"Response: {response.message}\")\n",
    "\n",
    "# Show the collected metrics\n",
    "print(\"\\n\\nAgent Metrics:\")\n",
    "import json\n",
    "print(json.dumps(middleware.get_metrics(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands.handlers.callback_handler import PrintingCallbackHandler\n",
    "\n",
    "# Create a simple agent\n",
    "simple_agent = Agent(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",  # Using Nova Lite model\n",
    "    tools=[current_time],\n",
    "    system_prompt=\"You are a helpful assistant that provides clear and informative responses.\"\n",
    ")\n",
    "\n",
    "result = simple_agent(\"What's the time in London?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback Handler\n",
    "The Strands Agents SDK provides two \"process present\" mechanisms:\n",
    "\n",
    "- **Standard logging**: For internal operations, debugging, and errors (primarily for developers)\n",
    "- **Callback system**: For user-facing output, streaming responses, and tool execution notifications\n",
    "\n",
    "Callbacks are configured through the callback_handler parameter when creating an Agent object. You can use built-in handlers (`PrintingCallbackHandler` by default), or create custom callback handlers to process streaming events according to your application's specific requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure the root strands logger\n",
    "logging.getLogger(\"strands\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_agent = Agent(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",  # Using Nova Lite model\n",
    "    tools=[current_time],\n",
    "    system_prompt=\"You are a helpful assistant that provides clear and informative responses.\",\n",
    "    callback_handler=PrintingCallbackHandler()\n",
    ")\n",
    "\n",
    "result = simple_agent(\"What's the time in London?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_agent = Agent(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",  # Using Nova Lite model\n",
    "    tools=[current_time],\n",
    "    system_prompt=\"You are a helpful assistant that provides clear and informative responses.\",\n",
    "    callback_handler=None\n",
    ")\n",
    "\n",
    "result = simple_agent(\"What's the time in London?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring\n",
    "By default, Strands Agents provides you complete metrics to track and analyze your agent's performance. These metrics are automatically collected and can be accessed after agent execution. This data helps you optimize your agent's performance, monitor resource usage, and control operational costs without requiring any additional configuration.\n",
    "\n",
    "You can access these metrics programmatically to integrate with your monitoring systems or to generate performance reports for your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(result.metrics.get_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Token Usage and Costs\n",
    "\n",
    "For production systems, monitoring token usage and costs is critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.metrics.accumulated_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing\n",
    "\n",
    "Observability relies heavily on tracing to offer in-depth visibility into your agent's operations. By adhering to the OpenTelemetry standard, Strands Agents framework traces meticulously record the entire path of a request as it moves through your agent. This includes interactions with LLMs, data retrieval processes, tool utilization, and the handling of events within the loop.\n",
    "\n",
    "<img src=\"jeager.jpg\" width=\"750\" alt=\"jeager\">\n",
    "\n",
    "(image using Jeager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull and run Jaeger all-in-one container\n",
    "# Suppose you've install docker\n",
    "!sudo docker run -d --name jaeger \\\n",
    "  -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \\\n",
    "  -e COLLECTOR_OTLP_ENABLED=true \\\n",
    "  -p 6831:6831/udp \\\n",
    "  -p 6832:6832/udp \\\n",
    "  -p 5778:5778 \\\n",
    "  -p 16686:16686 \\\n",
    "  -p 4317:4317 \\\n",
    "  -p 4318:4318 \\\n",
    "  -p 14250:14250 \\\n",
    "  -p 14268:14268 \\\n",
    "  -p 14269:14269 \\\n",
    "  -p 9411:9411 \\\n",
    "  jaegertracing/all-in-one:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from strands.telemetry.tracer import get_tracer\n",
    "\n",
    "# Configure the tracer\n",
    "tracer = get_tracer(\n",
    "    service_name=\"strands-agents-svc\",\n",
    "    otlp_endpoint=\"http://localhost:4318\",\n",
    "    otlp_headers={\"Authorization\": \"Bearer TOKEN\"},\n",
    "    enable_console_export=True\n",
    ")\n",
    "\n",
    "# Create agent\n",
    "agent = Agent(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    tools=[current_time],\n",
    "    system_prompt=\"You are a helpful assistant that provides clear and informative responses.\"\n",
    ")\n",
    "\n",
    "# Execute a series of interactions that will be traced\n",
    "response = agent(\"Hi!\")\n",
    "print(response)\n",
    "\n",
    "# Ask a follow-up that uses tools\n",
    "response = agent(\"What's the time in London?\")\n",
    "print(response)\n",
    "\n",
    "# Each interaction creates a complete trace that can be visualized in your tracing tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Agent Observability\n",
    "\n",
    "When implementing observability for your Strands Agents, consider these best practices:\n",
    "\n",
    "1. Standardize instrumentation using OpenTelemetry\n",
    "2. Design for multiple consumers using fan-out architecture\n",
    "3. Optimize large data volume through filtering and sampling\n",
    "4. Shift observability left during agent development\n",
    "\n",
    "These practices should be implemented from day one to ensure reliable agent performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this chapter, we've explored various approaches to monitoring and observability for Strands Agents:\n",
    "\n",
    "1. Basic logging techniques for tracking agent activity\n",
    "2. Tracking token usage and costs\n",
    "3. Agent monitoring\n",
    "4. Tracing\n",
    "\n",
    "These techniques allow you to maintain visibility into how your agents are performing in production, identify issues early, and ensure cost-effective operation. As your agent systems grow in complexity, a robust observability strategy becomes increasingly important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Create a visualization that shows the distribution of response times for an agent over multiple requests\n",
    "2. Build a simple web dashboard (using a library like Dash or Streamlit) to display agent metrics in real-time\n",
    "3. Implement a token budget system that can automatically pause agent operations when a daily token limit is reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ending\n",
    "\n",
    "This concludes our course on Strands Agents. We've covered everything from the basics of creating agents, to using tools, customizing functionality, integrating with MCP, deploying to production, and building multi-agent systems. With the knowledge from all chapters in this course, you now have a comprehensive understanding of building, deploying, monitoring, and optimizing AI agents with the Strands Agents framework. \n",
    "\n",
    "🎉🎉🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
